# 补充：统计学原理

## 假设检验

<img src="markdown/image/image-20231010191242730.png" alt="image-20231010191242730" style="zoom: 50%;" />

### 建立假设

在假设检验中，常把一个被检验的假设称为原假设，用$H_0$表示，通常将不应轻易加以否定的假设作为原假设. 当$H_0$被拒绝时而接收的假设称为备择假设，用$H_1$表示，它们常常成对出现。



### 选择检验统计量，给出拒绝域形式

![image-20231007213714716](markdown/image/image-20231007213714716.png)



### 选择显著性水平

**假设检验会推断出两种结果:** 

1. 接受零假设，拒绝备择假设，也就是说实验组和对照组的指标是相同的

2. 接受备择假设，拒绝零假设，也就是说实验组和对照组的指标是不同的



<img src="markdown/image/image-20231007213722639.png" alt="image-20231007213722639" style="zoom:50%;" />



#### 第⼀类错误(Type I Error)

**定义：**统计上的定义是拒绝了事实上是正确的零假设 

> 在 A/B 测试中，零假设是两组的指标是相同的，当假设检验推断出两组指标不同，但事实上两组指标相同时，就是第⼀类错误。我们把两组指标不同称作阳性(Positive)。所以，第⼀类错误⼜叫假阳性(False Positive)。



> 发⽣第⼀类错误的概率⽤α表⽰，也被称为**显著⽔平(Significance Level)**。“显著”是指错误发⽣的概率⼤，统计上把发⽣率⼩于 5% 的事件称为⼩概率事件，代表这类事件不容易发⽣。因此显著⽔平⼀般也为 5%。 



#### 第⼆类错误(Type II Error)

**定义：**统计上的定义是接受了事实上是错误的零假设。

> 在 A/B 测试中，当假设检验推断出两组指标相同，但事实上两组指标是不同时，就是第⼆类错误。
>
> 我们把两组指标相同称作阴性(Negative)，所以第⼆类错误⼜叫假阴性(FalseNegative)。发⽣第⼆类错误的概率⽤β表⽰，统计上⼀般定义为 20%。



#### 势函数



![image-20231007213743666](markdown/image/image-20231007213743666.png)

### 给出拒绝域

#### p值

**定义：**在统计上，P 值就是**当零假设成⽴**时，我们所观测到的样本数据出现的概率 

> 在 A/B 测试 的语境下，P 值就是当对照组和实验组指标事实上是相同时，在 A/B 测试中⽤样本数据所观测到的“实验组和对照组指标相同”出现的概率。



> **p值是在零假设成立的情况下观测到样本数据或更极端情况发生的概率：**
>
> 当你进行假设检验时，你首先假设零假设是正确的。然后，你使用收集到的样本数据计算一个统计量，例如t值或Z值，根据这个统计量计算出一个p值。p值表示，如果零假设是正确的，那么观测到的样本数据或更极端情况发生的概率有多大。换句话说，p值衡量了你的观测数据与零假设一致的程度
>
> 与此相反的是，当我们在 A/B 测试中观测到“实验组和对照组指标不同”的概率(P 值) 很⼤，⽐如 70%，那么在零假设成⽴时，我们观测到这个事件还是很有可能的。所以这个时候我们接受零假设，拒绝备择假设，即两组指标是相同的。



在统计中，我们会⽤ P 值和显著⽔平α进⾏⽐较，⼜因为α⼀般取 5%，所以就⽤ P 值和5% 进⾏⽐较，就可以得出假设检验的结果了:

- 当P值⼩于5%时，我们拒绝零假设，接受备择假设，得出两组指标是不同的结论，⼜叫做结果显著
- 当P值⼤于5%时，我们接受零假设，拒绝备择假设，得出两组指标是相同的结论，⼜叫做结果不显著



#### 置信区间

置信区间是⼀个范围，⼀般前⾯会跟着⼀个百分数，最常⻅的是 95% 的置信区间。这是什么意思呢?在统计上，对于⼀个随机变量来说，有 95% 的概率包含总体平均值(Population mean)的范围，就叫做 95% 的置信区间。

置信区间的统计定义其实不是特别好懂，其实你可以直接把它理解为随机变量的波动范围，95% 的置信区间就是包含了整个波动范围的 95% 的区间。

> 置信⽔平表⽰置信区间包含真正的实验效应的频率（100次有多少次）



**A/B 测试本质上就是要判断对照组和实验组的指标是否相等，那怎么判断呢?**

答案就是计算实验组和对照组指标的差值$δ$。因为指标是随机变量，所以它们的差值$δ$也会是随机变量，具有⼀定的波动性。

这就意味着，我们就要计算出$δ$的置信区间，然后看看这个置信区间是否包括 0。

- 如果包括 0 的话，则说明$δ$有可能为 0，意味着两组指标有可能相同
- 如果不包括 0，则说明两组指标不同



> 例如，计算得出两组指标差值$δ$的 95% 置信区间为$ [0.005,0.011]$，不包含 0，也可以推断出两组指标显著不同。
>
> 若实验组和对照组分别的置信区间有95%区域不重叠，则实验效应应该是统计显著的，此时$p值<0.05$.



> $!$**理解95%：**95%表⽰经过许多研究计算得到的95%置信区间，例如进⾏100次研究计算，会得到100个对应的95%置信区间，⽽在这100个95%置信区间中，有多少频率、有⼏个置信区间会包含真正的实验效应。



## 区间估计类型

### * 区间估计概念及构造置信区间的方法

#### 区间估计概念

![image-20231007213402948](markdown/image/image-20231007213402948.png)



**同等置信区间、置信上限、置信下限**

![image-20231007213454341](markdown/image/image-20231007213454341.png)



#### *构造置信区间 - 轴度量法

![image-20231010185102178](markdown/image/image-20231010185102178.png)



### 单个正态总体参数的置信区间

####  方差$\sigma$已知

![image-20231007213517063](markdown/image/image-20231007213517063.png)

<img src="markdown/image/image-20231007213523126.png" alt="image-20231007213523126" style="zoom:30%;" />



#### 方差$\sigma$未知

![image-20231007213545655](markdown/image/image-20231007213545655.png)



#### 大样本置信区间

![image-20231007213556433](markdown/image/image-20231007213556433.png)

![image-20231007213602895](markdown/image/image-20231007213602895.png)





### 两个正态总体的置信区间 - $\mu_1-\mu_2$

![image-20231007213625581](markdown/image/image-20231007213625581.png)



#### **方差已知** 

<img src="markdown/image/image-20231010185432208.png" alt="image-20231010185432208" style="zoom:50%;" />



#### **方差未知** $\sigma_1^2=\sigma_2^2=\sigma^2$

<img src="markdown/image/image-20231010185443407.png" alt="image-20231010185443407" style="zoom:50%;" />



#### **当m和n 都很大时的近似置信区间**

可以证明：
$$
\frac{\overline{x}-\overline{y}-(\mu_1-\mu_2)}{\sqrt{\frac{s_x^2}{m}+\frac{s_y^2}{n}}} \sim N(0,1)
$$
由此可给出$\mu_1- \mu_2$的$1-\alpha$近似置信区间为:
$$
[\overline{x}-\overline{y}-\mu_{1-\alpha/2}\sqrt{\frac{s_x^2}{m}+\frac{s_y^2}{n}},\overline{x}-\overline{y}+\mu_{1-\alpha/2}\sqrt{\frac{s_x^2}{m}+\frac{s_y^2}{n}}]
$$



### 比例p检验

<img src="markdown/image/image-20231010185633617.png" alt="image-20231010185633617" style="zoom:67%;" />



#### 大样本情况

![image-20231010185653529](markdown/image/image-20231010185653529.png)



### 总结

#### 单个正态总体

| $\sigma$ | 检验方式 | 统计量                                         | $H_0$            | 拒绝域                              |
| -------- | -------- | ---------------------------------------------- | ---------------- | ----------------------------------- |
| 已知     | z检验    | $z=\frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}$ | $\mu \leq \mu_0$ | $W=\{z\geq z_{1-\alpha}\}$          |
|          |          |                                                | $\mu \geq \mu_0$ | $W=\{z\leq z_{-\alpha}\}$           |
|          |          |                                                | $\mu = \mu_0$    | $W=\{|z|\geq z_{1-\alpha/2}\}$      |
| 未知     | t检验    | $t=\frac{\sqrt{n}(\overline{x}-\mu_0)}{s}$     | $\mu \leq \mu_0$ | $W=\{t\geq t_{1-\alpha}(n-1)\}$     |
|          |          |                                                | $\mu \geq \mu_0$ | $W=\{t\leq t_{-\alpha}(n-1)\}$      |
|          |          |                                                | $\mu = \mu_0$    | $W=\{|t|\geq t_{1-\alpha/2}(n-1)\}$ |
| 大样本   | z检验    |                                                |                  |                                     |



#### 两个正态总体

> 此处**u检验**也叫**z检验**

![image-20231010190315493](markdown/image/image-20231010190315493.png)



#### 比例p检验

一般考虑为大样本情况，用z检验方法

| 检验方式 |                            统计量                            | $H_0$            | 拒绝域                         |
| :------: | :----------------------------------------------------------: | ---------------- | ------------------------------ |
|  z检验   | $ u=\frac{\sqrt{n}(\overline{x}-\theta_0)}{\sqrt{\sigma^2(\theta_0)}} \dot{\sim} N(0,1)  $ | $\mu \leq \mu_0$ | $W=\{z\geq z_{1-\alpha}\}$     |
|          |                                                              | $\mu \geq \mu_0$ | $W=\{z\leq z_{-\alpha}\}$      |
|          |                                                              | $\mu= \mu_0$     | $W=\{|z|\geq z_{1-\alpha/2}\}$ |



## AB实验的建设检验

A/B 测试的语境中，假设⼀般是指**关于实验组和对照组指标的⼤⼩的推断。** 

在假设检验中的“假设”是⼀对:零假设(Null Hypothesis)和备择假设(Alternative Hypothesis)，它们是完全相反的。

在 A/B 测试的语境下，零假设指的是实验组和对照组的指标是相同的，备择假设指的是实验组和对照组的指标是不同的。

### 单尾、双尾检验

单尾检验(One-tailed Test)和双尾检验(Two-tailed Test)这两个概念。

- 单尾检验⼜叫单边检验(One-sided Test)，它不仅在假设中说明了两个⽐较对象不同，并且还明确了谁⼤谁⼩，⽐如实验组的指标⽐对照组的指标⼤。

- 双尾检验⼜叫双边检验(Two-sided Test)，指的是仅仅在假设中说明了两个⽐较对象不同，但是并没有明确谁⼤谁⼩。

> 单边检验可能需要对数据有主观意识的代⼊，例如指标应该更⼤，或者更⼩，⽽双边检验不带有这种主观想法，只是单纯利⽤数据来判断相同还是不同。



#### 在 A/B 测试的实践中，更推荐使⽤双尾检验。

**原因如下：**

- 第⼀个原因是，双尾检验可以让数据⾃⾝在决策中发挥更⼤的作⽤。

  > 我们在实践中使⽤ A/B 测试，就是希望能够通过数据来驱动决策。**我们要尽量减少在使⽤数据前产⽣的任何主观想法来⼲扰数据发挥作⽤。** 
  >
  > 所以，双尾检验这种不需要我们明确谁⼤谁⼩的检验，更能发挥数据的作⽤。

- 第⼆个原因：双尾检验可以帮助全⾯考虑变化带来的正、负⾯结果。

  > 双尾检验可以同时照顾到正⾯和负⾯的结果，更接近多变的现实情况。但是单尾检验只会适⽤于其中⼀种，⽽且通常是我们期望的正⾯效果。



---

### 其他检验

检验有很多种，单尾检验和双尾检验，是从“假设”的⾓度来分类的。除此之外， 常⻅的“检验”还可以根据⽐较样本的个数进⾏分类，包括**单样本检验(One-Sample Test)、 双样本检验(Two-Sample Test)和配对检验(Paired Test)**



#### 各个检验的使⽤范围

- 当两组样本数据进⾏⽐较时，就⽤**双样本检验**

  > ⽐如 A/B 测试中实验组和对照组的⽐较。

- 当⼀组样本数据和⼀个具体数值进⾏⽐较时，就⽤**单样本检验**

  > ⽐如，我想⽐较极客时间⽤户的⽇均使⽤时间有没有达到 15 分钟，这个时候，我就可以把⼀组样本数据(抽样所得的极客时间⽤户的每⽇使⽤时间)和⼀个具体数值$15$来进⾏⽐较。

- 当⽐较同⼀组样本数据发⽣变化前和发⽣变化后时，就⽤**配对检验** 

  > ⽐如，我现在随机抽取 1000 个极客时间的⽤户，给他们“全场专栏⼀律 1 折”这个优惠，然后在这1000 个⼈中，我们会⽐较他们在收到优惠前⼀个⽉的⽇均使⽤时间，和收到优惠后⼀个⽉的⽇均使⽤时间。



> **在 A/B 测试中，使⽤双样本检验。**



---

### T检验、Z检验

主要看样本量的⼤⼩和是否知道**总体⽅差(Population Variance)**:

- 当我们不知道总体⽅差时，使⽤ T 检验
- 当我们已知总体⽅差，且样本量⼤于 30 时，使⽤ Z 检验



<img src="markdown/image/image-20230320191254900.png" alt="image-20230320191254900" style="zoom: 33%;" />



> 在统计中我们习惯说样本量⼤于30 就是很⼤的样本，就可以⽤样本⽅差来近似总体⽅差，这样我们就知道总体⽅差，就可以⽤Z检验了，但其实30只是经验值，⼤于30的总体⽅差也是样本⽅差近似的，所以如果准确的说的话样本量⼤于30，在总体⽅差未知的情况下，也要⽤T检验。



这些理论具体到 A/B 测试实践中，⼀个经验就是：**均值类指标⼀般⽤ T 检验，概率类指标⼀般⽤ Z 检验(⽐例检验)。**



> 在样本量⾜够⼤的情况下 T 分布近似于Z分布，所以如果你不知道该⽤t检验还是z检验，⽽**样本量够⼤时，直接⽤T分布即可**; 



> ⽐例检验(Proportion Test) 是，专指⽤于**检验概率类指标的 Z 检验**。 



### FAQ

> **AB测试是否也能转换成单样本检验?比如AB两组样本，用A样本的均值标准差，和B样本做单样本检验? 通常用excel的Z.TEST时会这么干，会有什么问题吗**
>
> 双样本检验是两个有波动性的随机变量在比较，单样本检验时一个随机变量和个常数比较，你把其中一个变量简化成一个常数肯定会丢失掉原数据的一些特征嘛结果肯定没有双样本检测准确的，所以A/B测试是不推荐单样本检测的。



> **如果不只两个实验可以用t或z检验吗? 一个对照组两个实验组，用实验组分别和对照组做假设检验吗?**
>
> 对的!你说的是A/B/n测试，这里面有不止一个实验组，这是后就要用实验组分别和对照组做假设检验



> **如何检验两个样本比率是否发生变化** 
>
> 用独立性检验也就是卡方检验来验证两个样本比率是否发生变化。



### 统计功效

#### 定义与理解

统计功效Power，又被称作 Statistical Power：**如果变体之间存在真实差异，检出出这个有意义的差值的概率（统计上指当真实有差异的时候拒绝零假设的概率）**

Power 的本质是概率，在 A/B 测试中，如果实验组和对照组的指标事实上是不同的，Power 指的就是通过 A/B 测试探测到两者不同的概率。

> 在实验组和对照组中事实上确实存在差异时，AB测试准确检测出差异的概率。
>
> Power越大，就越能探测到两组的不同。**把 Power 看成 A/B 测试的灵敏度就可以了** 



$\alpha=P(\text{reject null}\mid \text{null true})$

$\beta=P(\text{fail to reject}\mid \text{null false})$

$1-\beta = \text{sensitivity}$： 通常为80%

> 小样本：
>
> - $\alpha$ 小
> - $\beta$ 高
>
> 大样本：
>
> - $\alpha$ 不变
> - $\beta$ 更小



统计功效是在测试中检测出选件之间转化率真实差异的概率。由于转化事件存在随机性，因此即使两个选件之间的转化率在长期测试中存在实际差异，该测试可能也不会显示具有统计意义的显著差异。可以认为这就是运气不好或纯属偶然。我们将这种未能检测到转化率真实差异的情况称为漏报或 II 类错误。



#### 例子

我们先把用户分为对照组和实验组，其中:

- 对照组是正常的用户注册流程，输入个人基本信息一短信/邮箱验证注册成功实验组是，在正常的用户注册流程中，还加入了微信、微博等第三方账号登录的功能用户可以通过第三方账号一键注册登录

- 相信不用我说，你也能猜到，实验组用户的注册率肯定比对照组的要高，因为实验组帮用户省去了繁琐的注册操作。这就说明，在事实上这两组用户的注册率是不同的

那么，现在如果 A/B 测试有 80% 的 Power，就意味着这个 A/B 测试有 80% 的概率可以准确地检测到这两组用户注册率的不同，得出统计显著的结果。换句话说，这个 A/B 测试有 20% 的概率会错误地认为这两组用户的注册率是相同的
可见，Power 越大，说明 A/B 测试越够准确地检测出实验组与对照组的不同(如果两组事实上是不同的)



> 当对照实验的置信区间包含0，并不意味着置信区间中的零比其他值更有可能出现，实验很可能没有足够的统计功效。

