# 因果推断

## 为什么需要因果推断

统计学只告诉我们相关性，而现实场景中，更注重在因果性上。

> **统计学更关注在相关性上：** 
>
> 一个国家的人均巧克力消费量越高，出现诺贝尔奖获得者的比例越大
>
> **现实业务场景：** 
>
> 我们观察到了巧克力消费和诺奖数量，星座和违章人数的线性关系，但它没有告诉我们的是，巧克力消费和诺奖数量背后的共同原因可能是经济发达程度；而违章率高的星座在当地人口占比最高。

从对社会和业务更有意义的角度来说，我们想知道的是 ‘怎么做才能提升诺奖的数量’ 或者‘用户点击某功能能否带来加购/留存的提升’，而这样的问题就需要我们探究现象背后的原因，以及量化原因对于结果造成的影响，因果推断应运而生。基于反事实的思想和拟合随机实验的一系列方法，我们能够控制混杂变量，从观察性的数据中得出因果性结论，从而论证业务价值，给出落地建议。



### 什么是因果推断

> 摘自：[因果推断实战](https://mp.weixin.qq.com/s/etMqiZ0oKH9BtrGwLdJu2g)

因果推断是一门探究事物之间因果关系的学科，主要有两个基本框架:

- **因果图模型**

  着眼于因果关系的识别

- **潜在结果模型**

  较为常用的工具

站在数据分析的角度，潜在结果模型更加通俗易懂。我们使用潜在结果模型来给出因果推断的严谨定义。



### 什么时候用？

条件允许的情况下，AB test是最佳的因果推断方法之一。但ab test也有自己的局限性：

1. AB test不可进行：比如我们不能强迫一组用户‘吸烟’，另一组用户‘不吸烟’去观察吸烟对健康的危害；
2. AB test成本太高：当线上实验的选择太多，而产品的流量/时间成本是有限时，逐一对每一个实验都进行测试显然不现实；
3. 其他特殊原因



### 基本概念及符号

#### **干预** $D_i$

用来表示实验对象是否接受某一种干预：
$$
D_i=
\begin{cases}
0& 未受到干预\\
1& 受到干预
\end{cases}
$$


#### **潜在结果** $Y_i$

$$
潜在结果= \ 
\begin{cases}
Y_i(0), \ D_i=0\\
Y_i(1), \ D_i=1
\end{cases}
$$

表示实验对象受到/未受到干预时产生的结果，其相反的结果为**反事实结果**



---

## 处置效应

### 个体处置效应

处置行为$D_i$对个体$𝑖$的处置效应是指个体$𝑖$接受处置潜在结果和没接受处置潜在结果的差异。即:
$$
\begin{align}
D_i对个体 \ i \ 的处置效应&=\gamma(i)\\
&=Y_i(1)-Y_i(0)
\end{align}
$$

### 平均处置效应

- 接受处置个体的平均处置效应**ATT**：
  $$
  \begin{align}
  ATT &= E[\gamma(i)|D_i=1]\\
  &=E[Y_i(1)-Y_i(0)|D_i=1] \\
  &=E[Y_i(1)|D_i=1]-E[Y_i(0)|D_i=1]
  
  \end{align}
  $$
  𝐴𝑇𝑇是我们最关注的结果，因为这是处置行为的直接后果

  

- 未接受处置个体的平均处置效应**ATU**:
  $$
  \begin{align}
  ATU &= E[\gamma(i)|D_i=0]\\
  &=E[Y_i(1)-Y_i(0)|D_i=0] \\
  &=E[Y_i(1)|D_i=0]-E[Y_i(0)|D_i=0]
  
  \end{align}
  $$
  
- 总体平均处置效应**ATE**:
  $$
  \begin{align}
  ATE &= E[\gamma(i)]\\
  &=E[Y_i(1)]-E[Y_i(0)]
  \end{align}
  $$
  𝐴𝑇𝐸衡量一项处置行为对所有（包含已接受处置和未接受处置）个体的平均处置效应

  

  𝐴𝑇𝐸是𝐴𝑇𝑇和𝐴𝑇𝑈的加权平均：
  $$
  ATE=\omega \times ATT+(1-\omega) \times ATU
  $$
  

### 观测结果及其带来的误差

对个体$𝑖$，我们不可能同时观测得到两种潜在结果，因此无法直接计算处置效应($\gamma(i)$)，这是Holland提出的**因果推断的根本难点**。

我们观测到的结果只是个体根据它的接受处置状态而显现出来对应的潜在结果，称之为**观测结果**，观测结果$Y_i$可以表示为潜在结果和处置状态的函数：
$$
Y_i=Y_i(0)+[Y_i(1)-Y_i(0)] \times D_i
$$
**处置组与观测组：**

- $D_i = 1$的一组称为处置组
- $D_i = 0$的一组称为观测组



#### 使用观测结果估计处置效应可能的偏差

**定义**
$$
\begin{align}
ATT &= E[Y_i(1)|D_i=1]-E[Y_i(0)|D_i=1]=T1-T0\\
\\
ATU &=E[Y_i(1)|D_i=0]-E[Y_i(0)|D_i=0]=C1-C0\\
\\
ATE &= \omega \times ATT+(1-\omega)\times ATU\\
&=\omega \times(T1-T0)+(1-\omega)\times(C1-C0)
\end{align}
$$


##### 偏差来源

根据定义，使用观测结果计算处置效应的方法是：直接使用处置组平均观测结果$T1$减去控制组平均观测结果$C(0)$，即
$$
T1-C0
$$
该估计量被称为**朴素估计量**



**公式拆解分析**

朴素估计量对于ATT、ATU、ATE的估计误差：
$$
\begin{align}
T1-C0&=[T1-T0]+[T0-C0]\\
&=ATT+ATT的估计误差\\
\\
T1-C0&=[C1-C0]+[T1-C1]\\
&=ATU+ATU的估计误差\\
\\
T1-C0&=[\omega(T1-T0)+(1-\omega)(C1-C0)]+ \  [\omega(T1-C0)+(1-\omega)(T1-C1)] \\
&=ATE+ATE的估计误差\\
\end{align}
$$


采用朴素估计量估计处置效应产生偏差的根本原因，是因为**接受处置与否并非随机**，即**是否接受处置与潜在结果是相关的**

> - 选择服药的人通常是在未服药情况下健康水平较低，或者是服药效果较好的人
> - 企业选择进行治理改造，通常是在未改造情况下业绩水平较低或者改造效果较好的企业



#### 改进方法1：随机分配

在随机分配中，潜在结果的好坏不会影响处置的分配。即个体的潜在结果和处置状态是独立的，用公式表示为：
$$
Y_i \perp D_i
$$
上述条件称为潜在结果**独立假设**，其包含两个独立性，即
$$
\{Y_i(1),Y_i(0)\} \perp D_i
$$

- $Y_i(1) \perp D_i$，意味着$E[Y_i(1)|D_i=1]=E[Y_i(1)|D_i=0]=E[Y_i(1)]$，也就意味着$T1=C1$

- $Y_i(0) \perp D_i$，意味着$E[Y_i(0)|D_i=1]=E[Y_i(0)|D_i=0]=E[Y_i(0)]$，也就意味着$T0=C0$

  

若$T0=C0$，则
$$
\begin{align}
T1-C0&=[T1-T0]+[T0-C0]\\
&=ATT+ATT的估计误差\\
&=ATT+0\\
&=ATT
\end{align}
$$

> 随机分配是一种很理想的研究方法。然而在社会科学实践中，这种方法实际上很少使用



#### 改进方法2：控制可观测变量

如果并非随机分配，那么处置组和控制组的平均潜在结果就可能存在差异，但如果**潜在结果的差异是由于个体的可观测特征造成的**，我们可以通过消除可观测个体特征差异，即**控制可观测特征去消除选择性偏差**。



对于有相同的$𝑋_𝑖 = 𝑥$的处置组和平均组，如果我们要估计$ATT(𝑥)$ ，用处置组平均观测结果减去控制组平均观测结果得到：
$$
\begin{align}
T1(x)-C0(x)&=[T1(x)-T0(x)]+[T0(x)-C0(x)]\\
&=ATT(x)+ATT(x)的估计误差
\end{align}
$$
我们看到如果$ATT(𝑥)$没有偏差，需要$T0(𝑥) − C0(𝑥) = 0$，即：
$$
E[Y_i(0)|D_i=1,X_i=x]=E[Y_i(0)|D_i=0,X_i=x]=E[Y_i(0)|X_i=x]
$$
这个条件称为**平均未接受处置潜在结果条件均值独立于处置变量**，即对于有相同可观测特征的处置组和观测组，它们的平均未接受处置的潜在结果是一样的。
$$
E[Y_i(0)|D_i,X_i]=E[Y_i(0)|X_i]
$$
当这个条件成立时，我们可以用观测结果得到
$$
ATT(x) =T1(x)-C0(x)
$$
且对于所有实验对象的ATT，有
$$
ATT=\sum_x p(x|D=1) \times ATT(x)\\
𝑃(𝑥|𝐷 = 1)是接受处置个体里具备特征𝑋_𝑖 = 𝑥的个体所占比例。
$$

> ATU、ATE同理

这个假设称为平均潜在结果条件独立于处置变量，简称**条件均值独立假设(CMI)**:
$$
\{Y_i(1),Y_i(0)\} \perp D_i|X_i
$$




---

## 匹配方法

**基于可观测特征的选择** 

“基于可观测特征的选择”情况下的因果路径图

![image-20231002191954296](/Users/siheng_huang/Desktop/markdown/image/image-20231002191954296.png)



匹配方法就是通过控制可观测变量，解决基于可观测变量自选择造成偏差的一种方法。

在匹配方法里，所谓的控制可观测变量就是**将控制组和观测组的个体按可观测特征进行匹配**。

> 如按照年龄、职业、性别进行匹配



- 随机分配方法保证了处置组和控制组的可观测特征和不可观测特征的分布都是一样的

- 而**匹配方法只是保证了可观测特征是一样的**



使用匹配方法，我们希望不可观测特征并不影响是否接受处置。这也是匹配方法估计处置效应需要的假设条件。如果这个假设不成立，那么匹配方法就失效了；

因此匹配方法和回归方法都依赖一个很强的假设，即控制了可观测特征后，处置组和控制组的不可观测特征也就不存在差异。



### 匹配方法的假设条件

#### 条件独立假设

给定可观测特征后，潜在结果独立于处置状态，数学表达为：
$$
\{Y_i(1),Y_i(0)\} \perp D_i|X_i
$$

> 可以简单地理解为：在可观测变量$𝑋$给定的情况下，接受处置与否是随机分配的， 即不会因为潜在结果的好坏而决定是否接受处置。



#### 共同支撑域条件

给定可观测特征$𝑋_𝑖 = 𝑥$，个体接受处置的概率大于0并小于1。数学表达为
$$
0 < 𝑃 (𝐷_𝑖|𝑋_𝑖=x)  < 1
$$
共同支撑域条件也被称为重叠条件，原因是其确保了对于给定的观测特征$𝑋_𝑖 = 𝑥$，有一些个体接受了处置，有一些没有，即同时存在处置组和控制组，这才可能估计处置效应。

> 例如对于30岁的人，我们必须同时观测到有些人服药，有些人没服药才能估计服药的效应。如果概率等于0，则只存在控制组。反之如果概率等于1，则只存在处置组。这两种情况下，我们都无法通过匹配而估计处置效应。



### 多维匹配 - 倾向得分匹配

#### 直接匹配

如下例，按照按企业资产(Assets)匹配

![image-20231002193415851](/Users/siheng_huang/Desktop/markdown/image/image-20231002193415851.png)

得到：

![image-20231002193439895](/Users/siheng_huang/Desktop/markdown/image/image-20231002193439895.png)

而后利用公式计算ATT、ATU、ATE



**局限性：**

- 当可观测特征维数增加，要在多维上进行直接匹配变得更加困难。即使$𝑋$只包含了2个变量，如果每个变量有10个值，需要匹配的特征组合就变成100个

- 当特征组合众多时，对于有些特征组合我们**可能无法同时找到对应的处置组和控制组样本**
- 如果可观测特征还包含**连续变量**，直接匹配就变得不可能了



### 倾向得分匹配 - PSM

#### 倾向得分

倾向得分法原理是通过函数关系将多维变量$𝑋$变换为一维的倾向得分$ps(X_i)$​之后，再根据倾向得分进行匹配

倾向得分是可观测特征为$𝑋_𝑖 = 𝑥$的个体接受处置的概率：
$$
𝑝𝑠(𝑋𝑖 = 𝑥) = 𝑃(𝐷𝑖 = 1|𝑋𝑖 = 𝑥)
$$
**前提条件：**

倾向得分之所以能够起到降维匹配的效果是因为证明了一条重要结论：
$$
\{Y_i(1),Y_i(0)\} \perp D_i|X_i 
\iff
\{Y_i(1),Y_i(0)\} \perp D_i|ps(X_i)
$$
即给定$𝑋_𝑖 = 𝑥$ ，潜在结果独立于处置状态等同于，给定$𝑝𝑠(𝑋_𝑖) = 𝑥$ ，潜在结果独立于处置状态。换句话说，倾向得分$𝑝𝑠(𝑋_𝑖) $总结了$𝑋_𝑖$变量中包含的所有相关信息



#### 倾向得分匹配的一般步骤

![image-20231002194525062](/Users/siheng_huang/Desktop/markdown/image/image-20231002194525062.png)



##### 第一步：估计倾向得分

由于处置参与（是否接受处置）通常是一个二分变量，因此我们在估计样本的倾向得分时，通常使用Probit模型或者Logit模型估计每个样本接受处置的概率，得到的概率即为匹配得分。

- **Probit模型**
  $$
  Pr(D_i=1|X_i)=\Phi(X_i^T \beta)
  $$

- **Logit模型**
  $$
  Pr(D_i=1|X_i)=F(X_i^T \beta)\\
  F(\beta X)=\frac{e^{\beta X}}{1+e^{\beta X}}
  $$
  

##### 第二步：匹配前均衡检验

- **匹配之前评估平衡性 - 分块均衡检测法** 

  检验对于相同倾向得分的处置组和控制组，它们的可观测特征均值是否相同，即

  $$
  E(X_i|D_i=1,ps(X_i))=E(X_i|D_i=0,ps(X_i))
  $$
  
  通常使用分块均衡检测法：
  
  - 根据匹配得分高低将样本分成若干个区间（块），通常以五个等分区间开始
  
  - 通过t统计值检验每个区间内处置组和控制组的平均匹配得分是否有差异
  
    如果有差异，把区间进一步细分直到在每个区间内两组的平均得分没有差异
  
  - 检验每个区间内控制组和处置组的可观测特征均值是否相同
  
    如果有显著差异，就需要重新调整倾向得分的估计方程，例如加入高阶变量和交叉项，然后再重新分块
    
  - 循环这个步骤直到每个细分区间内可观测特征均值没有显著差异



- **评估共同支撑域条件**

  我们需要评估控制组与处置组倾向得分的分布，如果两个组样本没有重合的倾向得分，或者重合的样本量太小，就会导致无法匹配或匹配偏差较大

  <img src="/Users/siheng_huang/Desktop/markdown/image/image-20231002195629678.png" alt="image-20231002195629678" style="zoom:50%;" />



##### 第三步：选择匹配方法

- **分块匹配法**

  - 先通过对样本按倾向得分划分为𝑄个区间，使得每个区间内处置组和控制组的平均倾向得分和

    可观测特征都达到均衡

  - 用每个区间内处置组和控制组观测结果的差异得到每个区间的处置效应，即
    $$
    ATT(q)=\overline{Y}_q^{Treatment}-\overline{Y}_q^{Control}\\  \\
    \overline{Y}_q^{Control}为控制组在区间\ 𝑞 \ 的平均结果值
    $$

  - 如果一共有𝑄个区间，最后对$𝐴𝑇𝑇(𝑞) $取加权平均得到平均处置效应：
    $$
    ATT = \sum_{q=1}^{Q}ATT\frac{N_q^{Treatment}}{N^{Treatment}}
    $$



- **近邻匹配法**

  近邻匹配法是对对处置组中的样本，选择控制组中倾向得分最接近的$𝑛$个样本作为其匹配样本。

  如果只取最近的一个，$𝑛 = 1$。如果取最近的五个，$𝑛 =5$

  

  **使用这个方法要决定控制组样本是否可以重复使用**

  > 如果允许重复使用，匹配的平均质量将增加，偏差（bias）会减少，代价是估计的方差（variance）会变大。
  >
  > 这是我们通常遇到的在选择估计变量时必须在偏差和方差之间权衡（trade-off between bias and variance）的问题。在实际运用中，可重复使用是比较常用的方法。

  

- **卡尺匹配法**
  - 为了解决近邻匹配法可能匹配到倾向得分差异较大的近邻，卡尺匹配法要求近邻匹配得分差异在一定的容忍程度（“卡尺”）内；
  - 卡尺匹配法的缺陷是如何界定容忍度没有标准的方法。如果容忍度太小，可能匹配的数量就较少或没有，方差就较大。如果容忍度较大，可能包括差异大的匹配样本，偏差就较大



- **半径匹配法**
  - 此方法允许容忍程度（“半径”）内的所有样本作为匹配样本。它不像“卡尺匹配法”只用最接近的𝑛个样本作为匹配样本。这种方法的好处是如果半径内的样本（匹配较好的样本）多，就都可以用作匹配；
  - 半径匹配法的缺点是它也必须确定最大容忍度。容忍度越大，匹配样本越多，但也越容易把匹配差异大的样本包括进来。



- **核匹配法**

  核匹配法对更接近处置组样本倾向得分的控制组样本赋予更高的权重。如果处置样本𝑖的匹配控制组样本

  有$𝑁_𝑖^{𝐶𝑜𝑛𝑡𝑟𝑜𝑙}$个，对于其中控制样本$𝑗$赋予的权重为：
  $$
  w_{i,j}=\frac{K(\frac{ps(x)_j-ps(x)_i}{h})}{\sum_{j=1}^{N_i^{Control}} K(\frac{ps(x)_j-ps(x)_i}{h})}
  $$

  - 其中，$K(·)$是一个核函数，$h$是核函数中需要的平滑参数，也称为带宽
  - 核函数通常可以选择Epanechnikov或Triangle密度函数。其缺点是带宽ℎ的选择比较困难。在实际工作中，检验核匹配结果需要检验结果对带宽选择的敏感度。



##### 第四步：匹配后均衡检验

- **标准化偏差**

  - 匹配之前处置组和控制组的特征$𝑋_𝑖$的标准化偏差为：
    $$
    SB_i^{before}=100 \frac{\overline{X}_{i,treatment}^{before}-\overline{X}_{i,control}^{before}}{\sqrt{0.5[Var(X_{i,treatment}^{before})+Var(X_{i,control}^{before})]}}
    $$

  - 匹配之后处置组和控制组的特征$𝑋_𝑖$的标准化偏差为：
    $$
    SB_i^{after}=100 \frac{\overline{X}_{i,treatment}^{after}-\overline{X}_{i,control}^{after}}{\sqrt{0.5[Var(X_{i,treatment}^{after})+Var(X_{i,control}^{after})]}}
    $$

  - 通过比较每个观测特征$SB_i^{before}$到$SB_i^{after}$的变化，可以得到倾向得分匹配的效果，偏差下降可用下面公式计算：
    $$
    BR_i=1-\frac{SB_i^{after}}{SB_i^{before}}
    $$



- **t检验**

  用t统计值直接检验处置组和控制组的每个特征$𝑋_𝑖$在匹配后的均值是否存在显著偏差

- **F检验**

  使用F 统计值对所有观测特征在匹配后是否还存在偏差进行共同检验



##### 第五步：计算处理效应

在匹配以及检验平衡特征后，可以计算平均处置效应：
$$
ATT=\frac{1}{N^{treatment}}\sum_{i\in I^{treatment}\cap S_p}\{Y_i-\sum_{j\in I^{control}\cap S_p}w_{ij}Y_j\}
$$

- $𝑁^{𝑇𝑟𝑒𝑎𝑡𝑚𝑒𝑛𝑡}$为处置组样本个数，$𝐼^{𝑇𝑟𝑒𝑎𝑡𝑚𝑒𝑛𝑡}$是处置组集，$𝑆_p$是共同支撑域集，$𝐼^{𝑇𝑟𝑒𝑎𝑡𝑚𝑒𝑛𝑡} ∩ 𝑆_p$是有共同支撑域的处置组样本，$𝑌_𝑖$是处置组里的样本$𝑖$的观测值;

- $𝑁^{Control}$为处置组样本个数，$𝐼^{Control}$是处置组集，$𝑆_p$是共同支撑域集，$𝐼^{Control} ∩ 𝑆_p$是有共同支撑域的处置组样本，$𝑌_j$是处置组里的样本$j$的观测值;

- $w_{ij}$是匹配的权重，不同匹配方法区别在于赋予的权重不同。





#### 总结

- 由于倾向匹配可采用的匹配方法较多，需要选择的参数也较多，实际应用中通常使用多种匹配方法和不同参数检验其稳健性；
- 并且尝试不同“共同支撑域”的要求。例如可以去掉没有共同支撑域的样本。也可以去掉“薄的共同支撑域”的样本，而只用“厚的共同支撑域”；
- 倾向匹配方法需要研究人员的主观判断较多，这也是使用倾向匹配方法的主要弱点



---



## 双重差分法

**定义**

在某个时间节点$t$进行处置，

- $T_{after}$代表处置组在$t$后的平均观测值
- $T_{before}$代表处置组在$t$前的平均观测值
- $C_{after}$代表控制组在$t$后的平均观测值
- $C_{before}$代表控制组在$t$前的平均观测值



### 单重差分

处置后平均观测值为$T_{after}$，但我们无法观测到处置组在t后，未进行处置的观测值$T_{after}^{'}$，因此无法直接计算税改对处置组的处置效应
$$
ATT=T_{after}-T^{'}_{after}
$$
估计反事实结果$T_{after}^{'}$的最直接的思路是“单重差分法”。通常有两种方法：

- **横截面单重差分法：**$T_{after}^{'}=C_{after}$ 
  $$
  \begin{align}
  ATT&=T_{after}-C_{after}\\
  &=E(Y_i(1)|Treat=1)-E(Y_i(1)|Treat=0)\\
  &=\beta_0+\beta_1+E(e_{it}|Treat=1)-\beta_0+E(e_{it}|Treat=0)\\
  &=\beta_1+[E(e_{it}|Treat=1)-E(e_{it}|Treat=0)]
  \end{align}
  $$
  如果这个模型回归得到的$𝑇𝑟𝑒𝑎𝑡_𝑖$的系数$\hat\beta_1$能够得到$𝛽_1$无偏估计的条件是
  $$
  E(e_{it}|Treat=1)-E(e_{it}|Treat=0)=0
  $$
  即处置组和控制组在事件发生的时间$t$后，除了受处置与否影响的差异外，不存在其他差别，显然这个条件是很难成立的。



- **时间序列单重差分：**$T_{after}^{'}=T_{before}$ 
  $$
  \begin{align}
  ATT&=T_{after}-T_{before}\\
  &=E(Y_i(1)|Treat=1)-E(Y_i(0)|Treat=1)\\
  &=\beta_0+\beta_1+E(e_{it}|Treat=1)-\beta_0+E(e_{i}|Treat=1)\\
  &=\beta_1+[E(e_{it}|Treat=1)-E(e_{i}|Treat=1)]
  \end{align}
  $$
  如果这个模型回归得到的$𝑇𝑟𝑒𝑎𝑡_𝑖$的系数$\hat\beta_1$能够得到$𝛽_1$无偏估计的条件是
  $$
  E(e_{it}|Treat=1)-E(e_{i}|Treat=1)=0
  $$
  即除了处置外没有其它因素造成处置组在时间$t$前后的平均业绩差别，这个条件也是很难成立的，因为某些宏观因素可能和税改在同一时点发生。



### 双重差分的直观理解

#### 平衡趋势假设

处置组在时间$t$ 前后的效应差异：
$$
T_{after}-T_{before}=处置造成的差异+其他因素造成的差异
$$
控制组在时间$t$ 前后的效应差异：
$$
C_{after}-C_{before}=其他因素造成的差异
$$
两者做差，有:
$$
\begin{align}
[T_{after}-T_{before}]-[C_{after}-C_{before}]=&处置造成的差异 \\&+其他因素造成的处置组差异
-其他因素造成的控制组差异
\end{align}
$$
当$其他因素造成的处置组差异-其他因素造成的控制组差异=0$时，即可得
$$
[T_{after}-T_{before}]-[C_{after}-C_{before}]=处置效应
$$


> 平衡趋势假设：
>
> 如上所述，需满足$其他因素造成的处置组差异\ = \ 其他因素造成的控制组差异$，也就是说其它因素对处置组和控制组在处置前后平均业绩变化的影响是相同的



#### 差异不变假设

处置组与控制组在时间$t$ 后的效应差异：
$$
T_{after}-C_{after}=处置造成的差异+其他因素造成的在时间t后的差异
$$
处置组与控制组在时间$t$ 前的效应差异：
$$
T_{before}-C_{before}=其他因素造成的在时间t前的差异
$$
两者做差，有:
$$
\begin{align}
[T_{after}-C_{after}]-[T_{before}-C_{before}]=&处置造成的差异 \\&+其他因素造成的时间t之前的差异
-其他因素造成的t之前的差异
\end{align}
$$
当$其他因素造成的时间t之后差异-其他因素造成的时间t之前差异=0$时，即可得
$$
[T_{after}-C_{after}]-[T_{before}-C_{before}]=处置效应
$$

> 差异不变假设：在时间$t$ 的前后，除处置外其他因素造成的差异时相同的。



### 双重差分模型

基本模型：
$$
Y_{it}=\beta_0+\beta_1T_i+\beta_2After_t+\beta_3T_i \times After_t+e_{it}\\
模型满足: E(e_{it}|T_i,After_t)=0
$$
<img src="/Users/siheng_huang/Desktop/markdown/image/image-20231004160841040.png" alt="image-20231004160841040" style="zoom:50%;" />

其中：
$$
\begin{align}
T_{before}\triangleq A &=  \beta_0+\beta_1 \\
T_{after}\triangleq B &=  \beta_0+\beta_1+\beta_2+\beta_3 \\
\\
C_{before}\triangleq C &=  \beta_0 \\
C_{after}\triangleq D &=  \beta_0+\beta_2 \\
\end{align}
$$
 因此，处置效应为：
$$
\begin{align}
[T_{after}-T_{before}]-[C_{after}-C_{before}]&=[B-A]-[D-C]\\
&=\beta_3
\end{align}
$$

### 假设条件的检验

**主要是考察处置组和控制组在事件发生前被解释变量的变化趋势是否一致**

- 比较处置组和控制在事件前趋势差异

  比较$\beta_1$的差异

- 安慰剂检验(Placebo Test）

  > 具体来说，这是一个对"平行趋势"假设的间接检验。如果我们可以确信在干预发生之前的任何时间点，处理组和对照组的差异都不是由于干预造成的，那么我们就更有信心相信干预之后的差异确实是由于干预造成的。
  >
  > 为了进行安慰剂检验，研究者通常会假设在一个虚构的时间点（通常是干预之前的某个时间点）发生了一个“假的”或“虚构的”干预。然后使用did方法估计这个“假的”干预的效果。如果我们发现在这个虚构的干预时间点，处理组和对照组之间的差异是显著的，那么这可能意味着我们的平行趋势假设是不成立的，因此我们的DiD估计是受到偏见的。



---

## DID + PSM

### DID和PSM各自的局限性

#### DID的局限性

1. 需要满足**平行趋势假设**：DID 的关键假设是处理组和控制组在干预前的趋势是平行的。这在实践中很难验证
2. 或者需要满足**时间差异不变假设**：DID 假设干预对控制组和处理组的效应是时间不变的。但在现实中，这种效应可能会随时间发生变化

这两条均难以满足，因此造成了DID方法的局限性。



#### PSM的局限性

1. 无法解决因**未观察到的变量引起的选择性偏误**，只能解决观察到的 
2. **共同支撑域条件**：匹配可能仅在共同支持范围内有效，这意味着处理组和控制组的倾向评分必须有重叠。如果两组在倾向评分上没有足够的重叠，匹配效果可能会受到影响 
3. **条件独立假设**过于严苛：PSM 假设有足够的控制变量来保证条件独立性假设，但这在实践中很难验证



此时，可以借助PSM的方法，构造一个与实验组满足平行趋势的控制组，接下来按照DID进行实验即可。

> 为何不直接使用PSM?
>
> PSM需要控制尽可能多的控制变量，以使分组变量完全随机
>
> 而对于有一些变量，一方面不可观测，另一方面又不随时间而改变，此时就可以使用PSM+DID的方法。



#### 结合PSM及DID的优势

1. **处理观察到的混淆因子**：PSM 可以确保处理组和控制组在观察到的混淆变量上是平衡的，从而减少这些混淆因子造成的偏误
2. **处理未观察到的混淆因子**：如果满足DiD的平行趋势假设，那么DiD 可以消除时间不变的未观察到的混淆因子的效应
3. **更好地满足平行趋势假设**：通过PSM，处理组和控制组更可能在干预前有相似的趋势，这使得DiD的平行趋势假设更有可能满足

结论是，通过结合PSM和DiD，研究者可以同时处理观察到的和未观察到的混淆因子，从而得到更为可靠的因果效应估计。但也需要注意，结合使用这两种方法需要更复杂的数据处理和分析，并且对其关键假设的满足情况进行详细的检查和诊断。



### 例子：离线因果推断在淘宝3D化价值分析上的实战

[离线因果推断在淘宝3D化价值分析上的实战](https://mp.weixin.qq.com/s/etMqiZ0oKH9BtrGwLdJu2g)

#### **业务背景和现状**

> 淘宝3D化为消费者提供多元化的场景导购内容，包括 2D 场景图文，3D 样板间，DIY 样板间等3D沉浸式体验。通过应用3D技术实现沉浸式商品导购体验，影响用户购买决策提升确定性，从而提升整体家装类目的导购转化率以及用户留存。
>
> <img src="/Users/siheng_huang/Desktop/markdown/image/640.png" alt="Image" style="zoom: 33%;" />
>
> <img src="/Users/siheng_huang/Desktop/markdown/image/640-20231005184417607.png" alt="Image" style="zoom: 33%;" />
>
> 



#### 具体问题

自项目启动以来，业务一直受困于一个问题：3D模型的IPV覆盖率未达预期，增速不佳。

3D模型是所有3D化产品的基石，没有模型意味着无法3D化。深入分析原因后发现，商家无法通过‘上模型’获得差异化权益、以及看不到产品的长期效果，共同导致了他们的配合意愿低。因此，验证3D化价值成为了当务之急。

通过对价值指标体系，受益方进行拆分，结合业务理解确立了如下的分析框架，并选择了用因果推断来验证不同3D化产品的价值，因为它可以真正回答‘**XX产品导致了加购率/成交率提升Y%**’这类问题：

<img src="/Users/siheng_huang/Desktop/markdown/image/640-20231005184513668.png" alt="Image" style="zoom:50%;" />



用户可以从商详页，首猜，主搜云卡片等渠道进入样板间，并在样板间内实现多点漫游，换风格，搭配家具，放我家等功能，给用户更场景化，私人化的体验。选取进入3D样板间的用户，利用倾向性得分匹配法（PSM）获取对照组的同质用户，分析用户在各个价值指标的差异。



#### 因果推断应用

##### PSM应用

1. 使用20余种用户基本特征，行为特征和家居偏好特征作为混杂因素，应用于匹配模型；
2. 匹配后数据表明，实验组用户的加购率+24.85%，手淘停留时长+27.68%，客单价+29.53%，带货带宽+5.98%，用户决策周期-5.75%

<img src="/Users/siheng_huang/Desktop/markdown/image/640-20231005192704075.png" alt="Image" style="zoom:70%;" />

通过PSM的分析结论，我们定量的验证了3D样板间对手淘各项指标的正向价值，进一步的，我们想要挖掘**背后是什么因素使得3D样板间产生了这些价值**：



##### 基于贝叶斯因果图 - 挖掘产生价值行为

> **贝叶斯因果图** 
>
> 计算变量之间的熵增，结合问题结构推理成对变量之间的因果关系；若两个节点间以一个单箭头连接在一起，表示其中一个节点是因，另一个是果。
>
> 以下图为例，smoking表示吸烟，其概率用$P(S)$表示；lung Cancer表示肺癌，一个人在吸烟的情况下得肺癌的概率用$P(C|S)$表示，X-ray表示需要照医学上的X光，肺癌可能会导致需要照X光，吸烟也有可能会导致需要照X光（所以smoking也是X-ray的一个因），所以，因吸烟且得肺癌而需要照X光的概率用$P(X|C,S)$表示。
>
> <img src="/Users/siheng_huang/Desktop/markdown/image/640-20231005192850798.png" alt="Image" style="zoom:67%;" />

用户在3D样板间里会产生大量复杂行为，包括点击商品锚点、切换场景、切换风格等等，而只有‘点击了商品并完成加购/购买’是完成样板间的价值实现。因此我们通过计算用户行为事件间的贝叶斯概率矩阵，推导出贝叶斯因果图，找到用户关键事件节点的根因行为。



考虑到特征覆盖度和用户使用频次，最终选取了10+样板间内行为特征和20+用户特征&偏好，并据此画出了因果图。大部分的因果链都是符合逻辑的，例如年龄指向结婚，结婚指向生育，收入指向有无房产等。它也揭示了一些有意义的箭头，我们据此给出了一定的建议，比如：

1. ‘有房’标签非常重要 ，是很多样板间内行为特征的‘因’。建议围绕‘有房’特征做好人群圈选，精准投放；

2. 用户对于新手引导的完成度高：新手引导的每一环都被保留在因果图上。但是当前的行为链路止步于‘切换房间’，没有引导用户至点击商品这一重度行为，建议完善；

   ![Image](/Users/siheng_huang/Desktop/markdown/image/640-20231005192931527.png)



在新手引导链路改造完成后，在引导完成率不降低的情况下，用户的加购率提升了28.93%。

离线因果推断验证了3D样板间的价值。在分析了对照组人群的运营可落地性后，我们转向了实时线上因果策略输出，从类目，商家，用户多个维度提供运营策略。

PSM输出的对照组人群，由于和实验组‘同质’，也可以被认为是样板间的潜力人群。我们对这一波潜客进行了随机分组，在淘宝搜索页上进行在线实验：



##### 基于双重差分法 - 计算业务增量价值

1. 在3D样板间的case中，因为潜客是用PSM挖掘后再随机分组的，所以认为满足平行趋势假设，DID可行；
2. PSM+DID也是常见的搭配，一起使用可以避开各自的局限性，起到1+1>2的效果；在后续的文章会展开。



通过DID计算线上3周的实验数据表明，加购率提升了6.73%，加购件数提升了1.26件，淘宝时长增长了17.26分钟。































